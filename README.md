[![Live Demo](https://img.shields.io/badge/ğŸ¤—%20Live%20Demo-DataFlow-blue)](https://huggingface.co/spaces/Spandan-139/dataflow)
[![CI](https://github.com/Spandan-139/dataflow/actions/workflows/ci.yml/badge.svg)](https://github.com/Spandan-139/dataflow/actions)

# ğŸ”„ DataFlow

A production-style ELT Analytics Platform built on GitHub Archive data with medallion architecture, Prefect orchestration, and DuckDB warehouse.

---

## Architecture
```
GitHub Archive (real events â€” pushes, PRs, stars, forks)
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Prefect ETL Flow     â”‚  Orchestration + retries
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â–¼            â–¼
ğŸ¥‰ Bronze     ğŸ¥ˆ Silver
Parquet       Parquet
Raw typed     Cleaned +
events        enriched
    â”‚            â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â–¼
      ğŸ¥‡ Gold
      Parquet
      Aggregated
      analytics
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    DuckDB Warehouse     â”‚  SQL-queryable consolidation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â–¼            â–¼
FastAPI API   Streamlit
Analytics     Dashboard
REST API      Visualizations
```

---

## Medallion Layers

**ğŸ¥‰ Bronze** â€” Raw GitHub Archive events ingested as-is. Schema enforced, typed, partitioned by date/hour. No business logic.

**ğŸ¥ˆ Silver** â€” Cleaned and enriched. Null filtering, repo owner/name splitting, event categorization (code/review/issues/social), org event flagging, temporal features.

**ğŸ¥‡ Gold** â€” Aggregated analytics tables. Top repos, event distributions, contributor rankings, hourly activity patterns. Optimized for query performance.

**ğŸ›ï¸ Warehouse** â€” DuckDB consolidates all Gold Parquet files into a single SQL-queryable database. Sub-second query times on 150k+ events.

---

## Tech Stack

| Layer | Technology |
|---|---|
| Orchestration | Prefect 3 |
| Ingestion | httpx + async |
| Processing | Polars |
| Storage | Parquet (Bronze/Silver/Gold) |
| Warehouse | DuckDB |
| API | FastAPI |
| Dashboard | Streamlit + Plotly |
| Dataset | GitHub Archive (gharchive.org) |

---

## Quick Start

### 1. Clone and install
```bash
git clone https://github.com/Spandan-139/dataflow.git
cd dataflow
python -m venv venv
venv\Scripts\activate  # Windows
pip install -r requirements.txt
pip install -e .
```

### 2. Run the ETL pipeline
```bash
python flows/etl_flow.py
```

### 3. Build the warehouse
```bash
make warehouse
```

### 4. Start the API
```bash
make api
# â†’ http://localhost:8000/docs
```

### 5. Start the dashboard
```bash
make dashboard
# â†’ http://localhost:8501
```

---

## API Endpoints

| Endpoint | Description |
|---|---|
| `GET /summary` | Total events, repos, contributors |
| `GET /repos?limit=10` | Top repos by activity |
| `GET /events` | Event type distribution |
| `GET /activity` | Hourly activity patterns |
| `GET /contributors?limit=10` | Top contributors |
| `POST /warehouse/rebuild` | Rebuild warehouse from Gold |

---

## Dataset

GitHub Archive records all public GitHub events. Each hourly file contains ~100k-200k events including pushes, pull requests, issues, stars, forks, and more.

- Source: [gharchive.org](https://www.gharchive.org)
- Format: newline-delimited JSON, gzipped
- Volume: ~150k-200k events per hour
- Coverage: All public GitHub activity since 2011

---

## Project Structure
```
dataflow/
â”œâ”€â”€ flows/
â”‚   â””â”€â”€ etl_flow.py          # Prefect DAG
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ gharchive.py     # GH Archive downloader + parser
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ bronze.py        # Raw â†’ Parquet
â”‚   â”‚   â”œâ”€â”€ silver.py        # Clean + enrich
â”‚   â”‚   â””â”€â”€ gold.py          # Aggregate analytics
â”‚   â”œâ”€â”€ warehouse/
â”‚   â”‚   â””â”€â”€ db.py            # DuckDB warehouse
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI analytics API
â”‚   â””â”€â”€ dashboard/
â”‚       â””â”€â”€ app.py           # Streamlit dashboard
â”œâ”€â”€ tests/
â”œâ”€â”€ Makefile
â””â”€â”€ requirements.txt
```

---

## Author

**Spandan** â€” B.Tech CSE @ SRMIST  
GitHub: [@Spandan-139](https://github.com/Spandan-139)